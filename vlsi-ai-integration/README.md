# VLSI-AI Integration Project

A complete system demonstrating hardware-accelerated deep learning inference through VLSI design. This project implements a CNN for MNIST digit recognition and compares performance between CPU, TensorFlow Lite, and custom hardware simulation.

## What This Project Does

- Trains a CNN model on MNIST handwritten digits
- Converts the model to TensorFlow Lite for optimization
- Simulates hardware acceleration using custom MAC and ReLU units
- Benchmarks performance across CPU, TFLite, and hardware implementations
- Provides a web dashboard for real-time performance visualization

## Project Structure

```
vlsi-ai-integration/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”‚
â”œâ”€â”€ data/                       # Generated models and test data
â”‚   â”œâ”€â”€ mnist/                  # MNIST test data
â”‚   â”‚   â”œâ”€â”€ x_test.npy
â”‚   â”‚   â””â”€â”€ y_test.npy
â”‚   â””â”€â”€ models/                 # Trained models
â”‚       â”œâ”€â”€ mnist_cnn.h5        # Keras model
â”‚       â””â”€â”€ mnist_cnn.tflite    # TensorFlow Lite model
â”‚
â”œâ”€â”€ scripts/                    # Executable scripts
â”‚   â”œâ”€â”€ train_model.py          # Train and save models
â”‚   â”œâ”€â”€ run_simulation.py       # Hardware simulation only
â”‚   â””â”€â”€ benchmark.py            # Full performance comparison
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ai_models/              # CNN training and model conversion
â”‚   â”‚   â”œâ”€â”€ cnn_trainer.py      # MNIST CNN implementation
â”‚   â”‚   â”œâ”€â”€ tflite_converter.py # TensorFlow Lite conversion
â”‚   â”‚   â””â”€â”€ model_utils.py      # Model loading utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ benchmarking/           # Performance analysis
â”‚   â”‚   â”œâ”€â”€ comparison_utils.py # Utility functions
â”‚   â”‚   â”œâ”€â”€ performance_analyzer.py # Performance analysis
â”‚   â”‚   â””â”€â”€ power_estimator.py  # Power consumption calculations
â”‚   â”‚
â”‚   â”œâ”€â”€ hardware/               # Hardware simulation
â”‚   â”‚   â”œâ”€â”€ simulation/         # Verilog simulation interface
â”‚   â”‚   â”œâ”€â”€ components/         # MAC, ReLU, and other units
â”‚   â”‚   â””â”€â”€ systemverilog/      # SystemVerilog hardware modules
â”‚   â”‚       â”œâ”€â”€ mac_unit.sv     # MAC unit implementation
â”‚   â”‚       â”œâ”€â”€ relu_unit.sv    # ReLU activation unit
â”‚   â”‚       â””â”€â”€ pipeline.sv     # Complete pipeline
â”‚   â”‚
â”‚   â”œâ”€â”€ integration/            # Bridge between AI and hardware
â”‚   â”‚   â”œâ”€â”€ tflite_hw_bridge.py # TFLite-Hardware interface
â”‚   â”‚   â””â”€â”€ pipeline_controller.py # Complete pipeline controller
â”‚   â”‚
â”‚   â””â”€â”€ dashboard/              # Web dashboard
â”‚       â”œâ”€â”€ api.py              # FastAPI backend
â”‚       â”œâ”€â”€ templates/          # HTML templates
â”‚       â”‚   â””â”€â”€ index.html      # Main dashboard page
â”‚       â””â”€â”€ static/             # CSS and JavaScript
â”‚           â”œâ”€â”€ css/
â”‚           â”‚   â””â”€â”€ styles.css  # Dashboard styling
â”‚           â””â”€â”€ js/
â”‚               â””â”€â”€ dashboard.js # Dashboard functionality
â”‚
â””â”€â”€ tests/                      # Unit tests
    â”œâ”€â”€ test_ai_models.py       # AI model tests
    â”œâ”€â”€ test_hardware.py        # Hardware simulation tests
    â””â”€â”€ test_integration.py     # Integration tests
```

## Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Train the Model

This creates the CNN model, converts to TFLite, and saves test data:

```bash
python scripts/train_model.py
```

Expected output:
```
âœ… Model training completed
âœ… Model saved to: data/models/mnist_cnn.h5
âœ… TFLite model saved to: data/models/mnist_cnn.tflite
âœ… Test data saved for benchmarking
```

### 3. Run Benchmark Comparison

Compare performance across all three implementations:

```bash
python scripts/benchmark.py
```

This shows detailed timing, speedup analysis, power consumption, and accuracy verification.

### 4. Launch Dashboard (Optional)

For interactive visualization:

```bash
python -m uvicorn src.dashboard.api:app --reload --host 0.0.0.0 --port 8000
```

Open http://localhost:8000 to see real-time performance charts.

## What You'll See

### Benchmark Results
- **Performance**: CPU vs TFLite vs Hardware timing comparison
- **Speedup**: How much faster hardware is compared to software
- **Power**: Estimated power consumption in ÂµW/mW/W
- **Accuracy**: Verification that all implementations give identical results

### Dashboard Features
- **Real-time Charts**: Interactive performance comparison graphs
- **Hardware Metrics**: Clock cycles, MAC operations, ReLU operations
- **Power Analysis**: Total power consumption and energy per inference
- **Accuracy Verification**: Ensures all implementations match
- **Live Logging**: Real-time benchmark progress updates

### Example Output
```
ðŸŽ¯ VLSI-AI INTEGRATION BENCHMARK RESULTS
========================================
ðŸ“Š PERFORMANCE COMPARISON (10 samples):
   CPU Inference Time:        0.1504 seconds
   TFLite Inference Time:     0.0890 seconds
   Hardware Simulation Time:  0.0320 seconds

âš¡ SPEEDUP ANALYSIS:
   CPU vs Hardware:           4.70x
   ðŸŽ‰ Hardware is 4.70x FASTER than CPU!

ðŸ”‹ POWER ANALYSIS:
   Hardware Power Consumption: 1.234 mW
   Energy per inference:       3.946 ÂµJ
```

## Key Components

### AI Models
- **CNN Architecture**: 2 conv layers + 2 dense layers for MNIST
- **TensorFlow Lite**: Optimized model for mobile/edge deployment
- **Model Utils**: Loading and validation functions

### Hardware Simulation
- **MAC Units**: Multiply-accumulate operations with realistic timing
- **ReLU Units**: Hardware activation function implementation
- **SystemVerilog Modules**: Actual hardware description in `src/hardware/systemverilog/`
- **Pipeline Controller**: Complete integration pipeline management

### Benchmarking & Analysis
- **Power Estimation**: Based on operation counts and hardware characteristics
- **Performance Analysis**: Comprehensive timing and speedup calculations
- **Comparison Utils**: Utilities for cross-platform performance comparison
- **Energy Efficiency**: Per-inference energy consumption metrics

### Web Dashboard
- **FastAPI Backend**: RESTful API for benchmark data
- **Interactive Charts**: Chart.js powered visualizations
- **Real-time Updates**: Live performance monitoring
- **Responsive Design**: Works on desktop and mobile devices

## Understanding the Results

### Performance Metrics
- **CPU Time**: Standard TensorFlow inference on CPU
- **TFLite Time**: Optimized inference using TensorFlow Lite
- **Hardware Time**: Custom VLSI implementation simulation

### Power Analysis
- Values typically range from ÂµW to mW for realistic edge deployment
- Energy per inference shows efficiency for battery-powered devices
- Hardware usually wins on power efficiency vs raw compute power

### Accuracy Verification
- All three implementations should give identical predictions
- This ensures hardware acceleration doesn't compromise accuracy

## Customization

### Changing the Model
Edit `src/ai_models/cnn_trainer.py` to modify:
- Network architecture
- Training parameters
- Dataset (currently MNIST)

### Hardware Parameters
Modify `src/hardware/simulation/hardware_sim.py` for:
- Clock frequency assumptions
- Power consumption models
- Operation timing characteristics

### SystemVerilog Hardware
Actual hardware modules in `src/hardware/systemverilog/`:
- `mac_unit.sv` - Multiply-accumulate unit
- `relu_unit.sv` - ReLU activation function
- `pipeline.sv` - Complete inference pipeline

### Dashboard Appearance
Customize `src/dashboard/static/css/styles.css` for visual changes.

## Technical Details

- **Framework**: TensorFlow 2.x with Keras
- **Hardware**: SystemVerilog modules + Python simulation interface
- **Web**: FastAPI + Chart.js for dashboard
- **Testing**: pytest for comprehensive unit tests

## Troubleshooting

**Missing files error**: Run `python scripts/train_model.py` first

**Import errors**: Ensure all dependencies installed with `pip install -r requirements.txt`

**Dashboard not loading**: Check that uvicorn is installed and port 8000 is available

**Low speedup**: This is simulation - real hardware would show better performance

This project demonstrates the complete pipeline from AI model to hardware implementation, making it easy to understand the benefits of hardware acceleration for edge AI deployment.